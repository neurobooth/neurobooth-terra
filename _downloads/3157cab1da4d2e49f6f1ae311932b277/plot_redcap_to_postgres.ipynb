{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Ingest table from Redcap into Postgres\n\nThis example demonstrates how to create table from Redcap.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Mainak Jas <mjas@harvard.mgh.edu>\n\nimport os\n\nfrom redcap import Project, RedcapError\nfrom neurobooth_terra.ingest_redcap import fetch_survey, iter_interval\n\nimport psycopg2\nfrom neurobooth_terra import Table, create_table, drop_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us first define the surveys and their survey IDs that we want to fetch.\nThis information can be found on Redcap. To fetch Redcap data, you will\nalso need to define the NEUROBOOTH_REDCAP_TOKEN environment variable.\nYou will need to request for the Redcap API token from Redcap interface.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "survey_ids = {'consent': 84349, 'contact': 84427, 'demographics': 84429,\n              'clinical': 84431, 'falls': 85031, 'subject': 84426}\nsurvey_ids = {'subject': 84426, 'consent': 84349}\n\nURL = 'https://redcap.partners.org/redcap/api/'\nAPI_KEY = os.environ.get('NEUROBOOTH_REDCAP_TOKEN')\n\nconnect_str = (\"dbname='neurobooth' user='neuroboother' host='localhost' \"\n               \"password='neuroboothrocks'\")\n\nif API_KEY is None:\n    raise ValueError('Please define the environment variable NEUROBOOTH_REDCAP_TOKEN first')\n\nproject = Project(URL, API_KEY, lazy=True)\n\n# First create a connection to the database\nconn = psycopg2.connect(connect_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we fetch the metadata table. This table is the master table\nthat contains columns and their informations. It can be used to infer\ninformation about the columns: example, what choices are available for a\nparticular question.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Fetching metadata ...')\nmetadata = project.export_metadata(format='df')\nmetadata_fields = ['field_label', 'form_name', 'section_header',\n                   'field_type', 'select_choices_or_calculations',\n                   'required_field']\nmetadata = metadata[metadata_fields]\n# metadata.to_csv(op.join(data_dir, 'data_dictionary.csv'), index=False)\nprint('[Done]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we loop over the surveys and collect them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nimport hashlib\n\n# TODO: add test for iter_interval\nfor _ in iter_interval(wait=5, exit_after=2):\n\n    dfs = dict()\n    for survey_name, survey_id in survey_ids.items():\n        df = fetch_survey(project, survey_name, survey_id)\n        # convert NaN to None for psycopg2\n        dfs[survey_name] = df\n\n    # Now, we will add the consent table to the subject table so we can\n    # match subjects based on record_id\n    df_redcap = dfs['subject'].join(dfs['consent'], rsuffix='consent')\n    print(df_redcap.columns)\n\n    # Now, we will prepare the contents of the subject table in postgres\n    rows_subject = list()\n    rows_consent = list()\n\n    df_redcap = df_redcap[~pd.isna(df_redcap['first_name_birth'])]\n\n    for df_row in df_redcap.iterrows():\n        df_row = df_row[1]\n\n        subject_id = df_row['first_name_birth'] + df_row['last_name_birth']\n        subject_id = hashlib.md5(subject_id.encode('ascii')).hexdigest()\n\n        rows_subject.append((subject_id,\n                            df_row['first_name_birth'],\n                            df_row['middle_name_birth'],\n                            df_row['last_name_birth'],\n                            df_row['date_of_birth'],\n                            df_row['country_of_birth'],\n                            df_row['gender_at_birth'],\n                            df_row['birthplace']))\n        rows_consent.append((subject_id,\n                            'study1',  # study_id\n                            'Neuroboother',  # staff_id\n                            'REDCAP',  # application_id\n                            'MGH',  # site_id\n                            # None, # date (missing)\n                            # df_row['educate_clinicians_adults'],\n                            # df_row['educate_clinicians_initials_adult'],\n                            # bool(df_row['future_research_consent_adult'])\n        ))\n    for row_subject in rows_subject[:5]:\n        print(row_subject)\n\n    # Then we insert the rows in this table\n    cols_subject = ['subject_id', 'first_name_birth', 'middle_name_birth',\n                    'last_name_birth', 'date_of_birth', 'country_of_birth',\n                    'gender_at_birth', 'birthplace']\n    table_subject = Table('subject', conn)\n    table_subject.insert_rows(rows_subject, cols_subject)\n\n    table_consent = Table('consent', conn)\n    cols_consent = ['subject_id', 'study_id', 'staff_id', 'application_id',\n                    'site_id']\n    table_consent.insert_rows(rows_consent, cols_consent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will drop our tables if they already exist\nthis is just for convenience so we can re-run this script\nand create a new mock subject table and consent table to test our script\ndrop_table('subject', conn)\ndrop_table('consent', conn)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# table_id = 'subject'\n# datatypes = ['VARCHAR (255)', 'VARCHAR (255)', 'VARCHAR (255)', 'VARCHAR (255)',\n#              'date', 'VARCHAR (255)', 'VARCHAR (255)', 'VARCHAR (255)']\n# table_subject = create_table(table_id, conn, cols_subject, datatypes)\n\n# table_id = 'consent'\n# datatypes = ['VARCHAR (255)'] * len(cols_consent)\n# table_consent = create_table(table_id, conn, cols_consent, datatypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's do a query to check that the content is in there\nprint(table_subject.query())\nprint(table_consent.query())\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}