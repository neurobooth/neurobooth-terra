{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Ingest table from Redcap into Postgres\n\nThis example demonstrates how to create table from Redcap.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Mainak Jas <mjas@harvard.mgh.edu>\n\nimport os\nimport os.path as op\n\nimport json\nfrom redcap import Project, RedcapError\n\nfrom neurobooth_terra import Table\nfrom neurobooth_terra.ingest_redcap import fetch_survey, infer_schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us first define the surveys and their survey IDs that we want to fetch.\nThis information can be found on Redcap. To fetch Redcap data, you will\nalso need to define the NEUROBOOTH_REDCAP_TOKEN environment variable.\nYou will need to request for the Redcap API token from Redcap interface.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "survey_ids = {'consent': 84349, 'contact': 84427, 'demographics': 84429,\n              'clinical': 84431, 'falls': 85031, 'guid': 84426}\nsurvey_ids = {'guid': 84426}\n\nURL = 'https://redcap.partners.org/redcap/api/'\nAPI_KEY = os.environ.get('NEUROBOOTH_REDCAP_TOKEN')\n\nif API_KEY is None:\n    raise ValueError('Please define the environment variable NEUROBOOTH_REDCAP_TOKEN first')\n\nproject = Project(URL, API_KEY, lazy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we fetch the metadata table. This table is the master table\nthat contains columns and their informations. It can be used to infer\ninformation about the columns: example, what choices are available for a\nparticular question.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Fetching metadata ...')\nmetadata = project.export_metadata(format='df')\nmetadata_fields = ['field_label', 'form_name', 'section_header',\n                   'field_type', 'select_choices_or_calculations',\n                   'required_field']\nmetadata = metadata[metadata_fields]\n# metadata.to_csv(op.join(data_dir, 'data_dictionary.csv'), index=False)\nprint('[Done]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we loop over the surveys and print out the schema.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "json_schema = dict()\nfor survey_name, survey_id in survey_ids.items():\n    df = fetch_survey(project, survey_name, survey_id)\n    json_schema[survey_name] = infer_schema(df, metadata)\nprint(json.dumps(json_schema[survey_name], indent=4, sort_keys=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we will prepare the subject table in postgres\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import hashlib\nimport datetime\n\ndf = fetch_survey(project, 'guid', survey_ids['guid'])\ndf = df[df['guid_information_complete'] == 2]  # take only complete rows\n\nrows = list()\nfor df_row in df.iterrows():\n    df_row = df_row[1]\n    subject_id = df_row['guid_firstname'] + df_row['guid_lastname']\n    subject_id = hashlib.md5(subject_id.encode('ascii')).hexdigest()\n    dob = datetime.date(year=int(df_row['guid_yearofbirth']),\n                        month=int(df_row['guid_monthofbirth']),\n                        day=int(df_row['guid_dayofbirth']))\n    dob = dob.strftime(\"%y-%m-%d\")\n    rows.append((subject_id,\n                 df_row['guid_firstname'],\n                 df_row['guid_middlename'],\n                 df_row['guid_lastname'],\n                 dob,\n                 df_row['guid_countryofbirth'],\n                 df_row['guid_birthgender']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we will prepare the subject table in postgres\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import psycopg2\n\nconnect_str = (\"dbname='neurobooth' user='neuroboother' host='localhost' \"\n               \"password='neuroboothrocks'\")\n\nconn = psycopg2.connect(connect_str)\ntable_subject = Table('subject', conn, primary_key='subject_id')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}